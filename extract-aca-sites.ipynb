{
 "metadata": {
  "name": "extract-aca-sites"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting ACA site reports and maps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import urllib2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_file(name):\n",
      "    dir_name, file_name = os.path.split(name)\n",
      "    cache_dir_path = os.path.join('cache', dir_name)\n",
      "    cache_path = os.path.join(cache_dir_path, file_name)\n",
      "    if os.path.exists(cache_path):\n",
      "        return open(cache_path)\n",
      "    \n",
      "    root = 'http://www.arch.cam.ac.uk/aca/'\n",
      "    url = root + name\n",
      "    \n",
      "    if not os.path.exists(cache_dir_path):\n",
      "        os.makedirs(cache_dir_path)\n",
      "        \n",
      "    data = urllib2.urlopen(url).read()\n",
      "    open(cache_path, 'w').write(data)\n",
      "    \n",
      "    return open(cache_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = BeautifulSoup(get_file('excavationreports.html').read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "county_headings = soup.findAll('h2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counties = {}\n",
      "for c in county_headings:\n",
      "    name = c.get_text().strip()\n",
      "    if name == u'':\n",
      "        continue\n",
      "    counties[name] = c\n",
      "\n",
      "county_places = {}\n",
      "places = []\n",
      "for name, c in counties.items():\n",
      "    ul = c.findNext('ul')\n",
      "    for li in ul.findChildren('li'):\n",
      "        link = li.findChildren('a')[0]\n",
      "        href = link.get('href')\n",
      "        place_name = link.get_text().strip()\n",
      "        \n",
      "        if name in county_places:\n",
      "            county_places[name].append((place_name, href))\n",
      "        else:\n",
      "            county_places[name] = [(place_name, href),]\n",
      "            \n",
      "        places.append((place_name, name, href))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import geopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g1 = geopy.geocoders.GeoNames()\n",
      "g2 = geopy.geocoders.Google()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "place_names = list('%s, %s, UK' % (x[0], x[1]) for x in places)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for name in place_names:\n",
      "    r = g1.geocode(name, exactly_one=False)\n",
      "    if r is None or len(r) == 0:\n",
      "        r = g2.geocode(name, exactly_one=False)\n",
      "        \n",
      "    locs.append(r)\n",
      "    if r is None or len(r) == 0:\n",
      "        print('Cannot find: %s' % (name,))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ext_places = []\n",
      "for place, ls in zip(places, locs):\n",
      "    geocodes = []\n",
      "    geocodes.extend(place)\n",
      "    if ls is None or len(ls) == 0:\n",
      "        geocodes.extend((None, None))\n",
      "    else:\n",
      "        geocodes.extend(ls[0][1])\n",
      "    ext_places.append(geocodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('places.csv', 'w') as f:\n",
      "    w = csv.writer(f)\n",
      "    w.writerow(('Town', 'County', 'Link', 'Latitude', 'Longitude'))\n",
      "    for r in ext_places:\n",
      "        w.writerow(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "place_doc = []\n",
      "for town, county, href, lat, lng in ext_places:\n",
      "    f = BeautifulSoup(get_file(href).read())\n",
      "    years = {}\n",
      "    for h in f.findAll('h2'):\n",
      "        title = h.get_text().strip()\n",
      "        if re.match('[0-9]+', title):\n",
      "            links = h.findNext('table').findAll('a')\n",
      "            link_rows = []\n",
      "            for l in links:\n",
      "                link_title = l.get_text().strip()\n",
      "                link_url = l.get('href')\n",
      "                link_rows.append({ 'description': link_title, 'href': link_url })\n",
      "                try:\n",
      "                    get_file(link_url)\n",
      "                except urllib2.HTTPError:\n",
      "                    print('Error getting link %s.' % (link_url,))\n",
      "            years[title] = link_rows\n",
      "    \n",
      "    record = {\n",
      "        'name': town, 'county': county, 'href': href,\n",
      "        'latlng': (lat, lng),\n",
      "        'digs': years,\n",
      "    }\n",
      "    place_doc.append(record)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "json.dump(place_doc, open('places.json', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}